# -*- coding: utf-8 -*-
"""TreeNutClassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e5FzwKhDmCHlq2NKUxrXKHyT5Ebs0bTe
"""

#Import libraries

import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf

from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from google.colab import files
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

"""UPLOAD FILES TO COLAB"""

from google.colab import files
uploaded = files.upload()

"""Resizing image files for faster porcessing

"""

# Resize all images in place or to new directory
def resize_images_in_folder(input_folder, output_folder=None, size=(224, 224), quality=85):
    if output_folder is None:
        output_folder = input_folder + "_resized"

    os.makedirs(output_folder, exist_ok=True)

    for root, dirs, files in os.walk(input_folder):
        for file in files:
            if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                input_path = os.path.join(root, file)

                # Maintain folder structure
                rel_path = os.path.relpath(root, input_folder)
                output_dir = os.path.join(output_folder, rel_path)
                os.makedirs(output_dir, exist_ok=True)

                output_path = os.path.join(output_dir, file.rsplit('.', 1)[0] + '.jpg')

                try:
                    img = Image.open(input_path)
                    img = img.convert('RGB')  # Ensure RGB for JPEG
                    img = img.resize(size, Image.Resampling.LANCZOS)
                    img.save(output_path, 'JPEG', quality=quality, optimize=True)
                    print(f"Resized: {file}")
                except Exception as e:
                    print(f"Error processing {file}: {e}")

# Use it
resize_images_in_folder('/content/Nuts', '/content/Nuts_small')

"""New resized file stats check"""

# Quick stats check
def check_results():
    original_count = 0
    original_size = 0
    resized_count = 0
    resized_size = 0

    # Count original files
    if os.path.exists('/content/Nuts'):
        for root, dirs, files in os.walk('/content/Nuts'):
            if '__MACOSX' in root:
                continue
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')) and not file.startswith('._'):
                    file_path = os.path.join(root, file)
                    original_count += 1
                    original_size += os.path.getsize(file_path)

    # Count resized files
    if os.path.exists('/content/Nuts_small'):
        for root, dirs, files in os.walk('/content/Nuts_small'):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    file_path = os.path.join(root, file)
                    resized_count += 1
                    resized_size += os.path.getsize(file_path)

    print("üéâ RESIZE RESULTS:")
    print(f"Original files: {original_count} images, {original_size/(1024*1024):.1f} MB")
    print(f"Resized files: {resized_count} images, {resized_size/(1024*1024):.1f} MB")

    if original_size > 0:
        reduction = ((original_size - resized_size) / original_size) * 100
        speedup = original_size / resized_size if resized_size > 0 else 0
        print(f"Size reduction: {reduction:.1f}%")
        print(f"Files are now {speedup:.1f}x smaller!")

        avg_original = original_size / original_count / 1024 if original_count > 0 else 0
        avg_resized = resized_size / resized_count / 1024 if resized_count > 0 else 0
        print(f"Average file size: {avg_original:.0f} KB ‚Üí {avg_resized:.0f} KB")

check_results()

dataset_path = '/content/Nuts_small'

# Check what's in Nuts_small now
print("Contents of /content/Nuts_small:")
for item in os.listdir('/content/Nuts_small'):
    item_path = os.path.join('/content/Nuts_small', item)
    if os.path.isdir(item_path):
        file_count = len([f for f in os.listdir(item_path)
                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        print(f"  üìÅ {item}: {file_count} images")
    else:
        print(f"  üìÑ {item}")

#Data Generators
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
NUM_CLASSES = 3  # Almonds, Walnuts, Cashews

print("Setting up data generators...")

# Training data with augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    validation_split=0.2  # 80% train, 20% validation
)

# Validation data - only rescaling
val_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Create generators
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

val_generator = val_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

print(f"Training samples: {train_generator.samples}")
print(f"Validation samples: {val_generator.samples}")
print(f"Classes: {train_generator.class_indices}")

# Display Sample Images from Each Class
import matplotlib.pyplot as plt
import numpy as np

print("Displaying sample images from each class...")

# Get a batch of images from the training generator
sample_batch = next(train_generator)  # Use next() function instead of .next()
sample_images = sample_batch[0]  # Images
sample_labels = sample_batch[1]  # One-hot encoded labels

# Convert one-hot labels to class indices
sample_classes = np.argmax(sample_labels, axis=1)

# Class names
class_names = ['Almonds', 'Cashews', 'Walnuts']

# Create subplot
fig, axes = plt.subplots(3, 5, figsize=(15, 9))

# Display 5 images from each class
for class_idx in range(3):  # 3 nut classes
    # Find indices for current class
    class_indices = np.where(sample_classes == class_idx)[0]

    # Display up to 5 images for this class
    images_to_show = min(5, len(class_indices))

    for i in range(images_to_show):
        if i < len(class_indices):
            img_idx = class_indices[i]
            axes[class_idx, i].imshow(sample_images[img_idx])
            axes[class_idx, i].set_title(f'{class_names[class_idx]}')
            axes[class_idx, i].axis('off')
        else:
            # Hide empty subplots
            axes[class_idx, i].axis('off')

plt.suptitle('Sample Images from Each Nut Class', fontsize=16)
plt.tight_layout()
plt.savefig('nut_samples.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"Sample images displayed and saved as 'nut_samples.png'")

# Create Model
print("Building model with transfer learning...")

# Load pre-trained MobileNetV2 (lightweight and efficient)
base_model = MobileNetV2(
    weights='imagenet',
    include_top=False,
    input_shape=(224, 224, 3)
)

# Freeze base model initially
base_model.trainable = False

# Add custom classification head
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(0.2),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(NUM_CLASSES, activation='softmax')  # 3 classes
])

# Compile model
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("Model created successfully!")
print(f"Output classes: {NUM_CLASSES} (Almonds, Cashews, Walnuts)")

# Show model summary
model.summary()

# Proper Train/Test Split

print("Creating proper train/test split...")

# Create new directories
train_dir = '/content/train'
test_dir = '/content/test'

for directory in [train_dir, test_dir]:
    if os.path.exists(directory):
        shutil.rmtree(directory)
    os.makedirs(directory)

# Split each class separately
for class_name in ['Almonds', 'Cashews', 'Walnuts']:
    # Create class directories
    os.makedirs(os.path.join(train_dir, class_name))
    os.makedirs(os.path.join(test_dir, class_name))

    # Get all images for this class
    class_path = os.path.join(dataset_path, class_name)
    all_images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    # Split 80/20
    train_images, test_images = train_test_split(all_images, test_size=0.2, random_state=42)

    # Copy files
    for img in train_images:
        src = os.path.join(class_path, img)
        dst = os.path.join(train_dir, class_name, img)
        shutil.copy2(src, dst)

    for img in test_images:
        src = os.path.join(class_path, img)
        dst = os.path.join(test_dir, class_name, img)
        shutil.copy2(src, dst)

    print(f"{class_name}: {len(train_images)} train, {len(test_images)} test")

print("\nProper split created!")

# Train Model

print("Training with proper train/test split...")

# Create NEW data generators using the split data
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True
)

# Test data - only rescaling (no augmentation)
test_datagen = ImageDataGenerator(rescale=1./255)

# Create generators pointing to the split folders
train_generator = train_datagen.flow_from_directory(
    '/content/train',  # Use the new train folder
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    '/content/test',   # Use the new test folder
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False  # Don't shuffle test data
)

print(f"‚úÖ Training samples: {train_generator.samples}")
print(f"‚úÖ Test samples: {test_generator.samples}")

# Setup callbacks for smart training
callbacks = [
    EarlyStopping(
        monitor='val_accuracy',
        patience=10,
        restore_best_weights=True,
        verbose=1
    ),
    ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.2,
        patience=5,
        min_lr=1e-7,
        verbose=1
    )
]

# Train the model with proper validation
history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // BATCH_SIZE,
    epochs=25,
    validation_data=test_generator,  # Use test set for validation
    validation_steps=test_generator.samples // BATCH_SIZE,
    callbacks=callbacks,
    verbose=1
)

print("‚úÖ Training completed with proper split!")

# Final Model Evaluation and Testing

print("Final Model Evaluation...")

# Reset test generator to ensure we get all samples
test_generator.reset()

# Get predictions on test set
print("Making predictions on test set...")
predictions = model.predict(test_generator, verbose=1)
predicted_classes = np.argmax(predictions, axis=1)

# Get true labels
true_classes = test_generator.classes
class_names = list(test_generator.class_indices.keys())

print(f"\nTest Set Results:")
print(f"Total test samples: {len(true_classes)}")

# Calculate accuracy
accuracy = np.mean(predicted_classes == true_classes)
print(f"Test Accuracy: {accuracy:.2%}")

# Detailed classification report
print("\nDetailed Classification Report:")
print(classification_report(true_classes, predicted_classes, target_names=class_names))

# Confusion Matrix
plt.figure(figsize=(8, 6))
cm = confusion_matrix(true_classes, predicted_classes)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.title('Nuts Classifier - Test Set Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Show per-class accuracy
print("\nPer-class Performance:")
for i, class_name in enumerate(class_names):
    class_mask = true_classes == i
    if np.sum(class_mask) > 0:
        class_accuracy = np.mean(predicted_classes[class_mask] == true_classes[class_mask])
        print(f"{class_name}: {class_accuracy:.2%} ({np.sum(class_mask)} samples)")

# Save the final model
print("\nüíæ Saving final model...")
model.save('/content/nuts_classifier_final.keras')  # Use new Keras format
print("Model saved as 'nuts_classifier_final.keras'")

print(f"\n Testing Complete!")
print(f"Your nuts classifier achieved {accuracy:.2%} accuracy on unseen test data!")