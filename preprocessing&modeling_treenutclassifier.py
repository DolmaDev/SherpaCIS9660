# -*- coding: utf-8 -*-
"""PreProcessing& Modeling-TreeNutClassifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e5FzwKhDmCHlq2NKUxrXKHyT5Ebs0bTe
"""

# Importing libraries
# Core libraries
import os
import numpy as np
import pickle

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# TensorFlow/Keras
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# Scikit-learn - Models
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

# Scikit-learn - Model evaluation and preprocessing
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Image processing
from PIL import Image
from skimage.transform import resize
from skimage.color import rgb2gray
from skimage.feature import local_binary_pattern, hog
from skimage.filters import prewitt_h, prewitt_v

"""UPLOAD FILES TO COLAB"""

from google.colab import files
uploaded = files.upload()

# Unzipping the Nuts.zip
import zipfile; print(" Starting extraction..."); zipfile.ZipFile('Nuts.zip', 'r').extractall('/content/'); print(" Extraction complete!"); import os; print(f" Contents: {[item for item in os.listdir('/content/Nuts') if os.path.isdir(os.path.join('/content/Nuts', item))]}")

"""Resizing image files for faster porcessing

"""

print("Starting image resizing..."); resize_images_in_folder('/content/Nuts', '/content/Nuts_small'); print("Resizing complete!"); import os; print(f"Resized folders: {[item for item in os.listdir('/content/Nuts_small') if os.path.isdir(os.path.join('/content/Nuts_small', item))]}")

# downloading resized file if colab crash
print("Creating backup zip..."); import shutil; shutil.make_archive('/content/Nuts_small_backup', 'zip', '/content/Nuts_small'); print("Backup zip created!"); from google.colab import files; files.download('Nuts_small_backup.zip'); print("Download complete!")

"""New resized file stats check"""

def check_results():
    def count_files(path):
        count, size = 0, 0
        if os.path.exists(path):
            for root, dirs, files in os.walk(path):
                if '__MACOSX' in root: continue
                for file in files:
                    if file.lower().endswith(('.png', '.jpg', '.jpeg')) and not file.startswith('._'):
                        count += 1; size += os.path.getsize(os.path.join(root, file))
        return count, size

    orig_count, orig_size = count_files('/content/Nuts')
    resized_count, resized_size = count_files('/content/Nuts_small')

    print("RESIZE RESULTS:")
    print(f"Original: {orig_count} images, {orig_size/(1024*1024):.1f} MB")
    print(f"Resized: {resized_count} images, {resized_size/(1024*1024):.1f} MB")

    if orig_size > 0:
        reduction = ((orig_size - resized_size) / orig_size) * 100
        speedup = orig_size / resized_size if resized_size > 0 else 0
        print(f"Reduction: {reduction:.1f}%, {speedup:.1f}x smaller")

print("Checking resize results..."); check_results(); print("Results check complete!")

dataset_path = '/content/Nuts_small'

# Check what's in Nuts_small now
print("Contents of /content/Nuts_small:")
for item in os.listdir('/content/Nuts_small'):
    item_path = os.path.join('/content/Nuts_small', item)
    if os.path.isdir(item_path):
        file_count = len([f for f in os.listdir(item_path)
                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])
        print(f"  üìÅ {item}: {file_count} images")
    else:
        print(f"  üìÑ {item}")

#Data Generators
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
NUM_CLASSES = 3  # Almonds, Walnuts, Cashews

print("Setting up data generators...")

# Training data with augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.15,
    zoom_range=0.15,
    horizontal_flip=True,
    validation_split=0.2  # 80% train, 20% validation
)

# Validation data - only rescaling
val_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Create generators
train_generator = train_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='training'
)

val_generator = val_datagen.flow_from_directory(
    dataset_path,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    subset='validation'
)

print(f"Training samples: {train_generator.samples}")
print(f"Validation samples: {val_generator.samples}")
print(f"Classes: {train_generator.class_indices}")

# Display Sample Images from Each Class
print("Displaying sample images from each class...")

# Get a batch of images from the training generator
sample_batch = next(train_generator)  # Use next() function instead of .next()
sample_images = sample_batch[0]  # Images
sample_labels = sample_batch[1]  # One-hot encoded labels

# Convert one-hot labels to class indices
sample_classes = np.argmax(sample_labels, axis=1)

# Class names
class_names = ['Almonds', 'Cashews', 'Walnuts']

# Create subplot
fig, axes = plt.subplots(3, 5, figsize=(15, 9))

# Display 5 images from each class
for class_idx in range(3):  # 3 nut classes
    # Find indices for current class
    class_indices = np.where(sample_classes == class_idx)[0]

    # Display up to 5 images for this class
    images_to_show = min(5, len(class_indices))

    for i in range(images_to_show):
        if i < len(class_indices):
            img_idx = class_indices[i]
            axes[class_idx, i].imshow(sample_images[img_idx])
            axes[class_idx, i].set_title(f'{class_names[class_idx]}')
            axes[class_idx, i].axis('off')
        else:
            # Hide empty subplots
            axes[class_idx, i].axis('off')

plt.suptitle('Sample Images from Each Nut Class', fontsize=16)
plt.tight_layout()
plt.savefig('nut_samples.png', dpi=150, bbox_inches='tight')
plt.show()

print(f"Sample images displayed and saved as 'nut_samples.png'")

# Feature extraction setup and sample processing
print("Feature extraction with before/after visualization...")

# Get sample images from each class
sample_batch = next(train_generator)
sample_images = sample_batch[0]
sample_labels = sample_batch[1]
sample_classes = np.argmax(sample_labels, axis=1)

# Find one image from each class
almond_idx = np.where(sample_classes == 0)[0][0]
cashew_idx = np.where(sample_classes == 1)[0][0]
walnut_idx = np.where(sample_classes == 2)[0][0]

sample_almond = sample_images[almond_idx]
sample_cashew = sample_images[cashew_idx]
sample_walnut = sample_images[walnut_idx]

# Parameters for feature extraction
radius = 1
n_points = 8 * radius
METHOD = 'uniform'

# Process Almond image
print("Processing Almond image...")
almond_resized = resize(sample_almond, (64, 64), anti_aliasing=True)
almond_gray = rgb2gray(almond_resized)
almond_lbp = local_binary_pattern(almond_gray, n_points, radius, METHOD)
almond_hog, almond_hog_image = hog(almond_gray, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1), visualize=True)
almond_h_edges = prewitt_h(almond_gray)
almond_v_edges = prewitt_v(almond_gray)

# Process Cashew image
print("Processing Cashew image...")
cashew_resized = resize(sample_cashew, (64, 64), anti_aliasing=True)
cashew_gray = rgb2gray(cashew_resized)
cashew_lbp = local_binary_pattern(cashew_gray, n_points, radius, METHOD)
cashew_hog, cashew_hog_image = hog(cashew_gray, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1), visualize=True)
cashew_h_edges = prewitt_h(cashew_gray)
cashew_v_edges = prewitt_v(cashew_gray)

# Process Walnut image
print("Processing Walnut image...")
walnut_resized = resize(sample_walnut, (64, 64), anti_aliasing=True)
walnut_gray = rgb2gray(walnut_resized)
walnut_lbp = local_binary_pattern(walnut_gray, n_points, radius, METHOD)
walnut_hog, walnut_hog_image = hog(walnut_gray, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1), visualize=True)
walnut_h_edges = prewitt_h(walnut_gray)
walnut_v_edges = prewitt_v(walnut_gray)

# Create comprehensive visualization of feature extraction
fig, axes = plt.subplots(4, 9, figsize=(27, 12))

# Row 1: Original images
axes[0, 0].imshow(sample_almond)
axes[0, 0].set_title('Original Almond', fontsize=10)
axes[0, 0].axis('off')

axes[0, 1].imshow(almond_resized)
axes[0, 1].set_title('Resized (64x64)', fontsize=10)
axes[0, 1].axis('off')

axes[0, 2].imshow(almond_gray, cmap='gray')
axes[0, 2].set_title('Grayscale', fontsize=10)
axes[0, 2].axis('off')

axes[0, 3].imshow(sample_cashew)
axes[0, 3].set_title('Original Cashew', fontsize=10)
axes[0, 3].axis('off')

axes[0, 4].imshow(cashew_resized)
axes[0, 4].set_title('Resized (64x64)', fontsize=10)
axes[0, 4].axis('off')

axes[0, 5].imshow(cashew_gray, cmap='gray')
axes[0, 5].set_title('Grayscale', fontsize=10)
axes[0, 5].axis('off')

axes[0, 6].imshow(sample_walnut)
axes[0, 6].set_title('Original Walnut', fontsize=10)
axes[0, 6].axis('off')

axes[0, 7].imshow(walnut_resized)
axes[0, 7].set_title('Resized (64x64)', fontsize=10)
axes[0, 7].axis('off')

axes[0, 8].imshow(walnut_gray, cmap='gray')
axes[0, 8].set_title('Grayscale', fontsize=10)
axes[0, 8].axis('off')

# Row 2: Local Binary Pattern
axes[1, 0].imshow(almond_lbp, cmap='gray')
axes[1, 0].set_title('Almond LBP', fontsize=10)
axes[1, 0].axis('off')

axes[1, 1].hist(almond_lbp.ravel(), bins=20, alpha=0.7, color='brown')
axes[1, 1].set_title('Almond LBP Histogram', fontsize=10)

axes[1, 2].axis('off')

axes[1, 3].imshow(cashew_lbp, cmap='gray')
axes[1, 3].set_title('Cashew LBP', fontsize=10)
axes[1, 3].axis('off')

axes[1, 4].hist(cashew_lbp.ravel(), bins=20, alpha=0.7, color='orange')
axes[1, 4].set_title('Cashew LBP Histogram', fontsize=10)

axes[1, 5].axis('off')

axes[1, 6].imshow(walnut_lbp, cmap='gray')
axes[1, 6].set_title('Walnut LBP', fontsize=10)
axes[1, 6].axis('off')

axes[1, 7].hist(walnut_lbp.ravel(), bins=20, alpha=0.7, color='gray')
axes[1, 7].set_title('Walnut LBP Histogram', fontsize=10)

axes[1, 8].axis('off')

# Row 3: HOG Features
axes[2, 0].imshow(almond_hog_image, cmap='gray')
axes[2, 0].set_title('Almond HOG', fontsize=10)
axes[2, 0].axis('off')

axes[2, 1].plot(almond_hog[:50], color='brown')
axes[2, 1].set_title('Almond HOG Features', fontsize=10)

axes[2, 2].axis('off')

axes[2, 3].imshow(cashew_hog_image, cmap='gray')
axes[2, 3].set_title('Cashew HOG', fontsize=10)
axes[2, 3].axis('off')

axes[2, 4].plot(cashew_hog[:50], color='orange')
axes[2, 4].set_title('Cashew HOG Features', fontsize=10)

axes[2, 5].axis('off')

axes[2, 6].imshow(walnut_hog_image, cmap='gray')
axes[2, 6].set_title('Walnut HOG', fontsize=10)
axes[2, 6].axis('off')

axes[2, 7].plot(walnut_hog[:50], color='gray')
axes[2, 7].set_title('Walnut HOG Features', fontsize=10)

axes[2, 8].axis('off')

# Row 4: Edge Detection
axes[3, 0].imshow(almond_h_edges, cmap='gray')
axes[3, 0].set_title('Almond H-Edges', fontsize=10)
axes[3, 0].axis('off')

axes[3, 1].imshow(almond_v_edges, cmap='gray')
axes[3, 1].set_title('Almond V-Edges', fontsize=10)
axes[3, 1].axis('off')

axes[3, 2].axis('off')

axes[3, 3].imshow(cashew_h_edges, cmap='gray')
axes[3, 3].set_title('Cashew H-Edges', fontsize=10)
axes[3, 3].axis('off')

axes[3, 4].imshow(cashew_v_edges, cmap='gray')
axes[3, 4].set_title('Cashew V-Edges', fontsize=10)
axes[3, 4].axis('off')

axes[3, 5].axis('off')

axes[3, 6].imshow(walnut_h_edges, cmap='gray')
axes[3, 6].set_title('Walnut H-Edges', fontsize=10)
axes[3, 6].axis('off')

axes[3, 7].imshow(walnut_v_edges, cmap='gray')
axes[3, 7].set_title('Walnut V-Edges', fontsize=10)
axes[3, 7].axis('off')

axes[3, 8].axis('off')

plt.tight_layout()
plt.savefig('nut_feature_extraction_visualization.png', dpi=150, bbox_inches='tight')
plt.show()

# Extract features from all images
print("Extracting features from all images...")
all_features = []
all_labels = []

# Reset generators to get all data
train_generator.reset()
val_generator.reset()

# Combine both generators
generators = [train_generator, val_generator]

total_processed = 0
for generator in generators:
    for i in range(len(generator)):
        batch_images, batch_labels = generator[i]

        for j, image in enumerate(batch_images):
            if total_processed % 50 == 0:
                print(f"Processing image {total_processed}")

            # Resize image to manageable size
            image_resized = resize(image, (64, 64), anti_aliasing=True)

            # 1. Color features (RGB channel means)
            rgb_features = np.mean(image_resized, axis=(0, 1))

            # 2. Convert to grayscale for texture and edge features
            gray_image = rgb2gray(image_resized)

            # 3. Local Binary Pattern features
            lbp = local_binary_pattern(gray_image, n_points, radius, METHOD)
            lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_points + 2,
                                     range=(0, n_points + 2), density=True)

            # 4. HOG features
            hog_features = hog(gray_image, orientations=8, pixels_per_cell=(8, 8),
                              cells_per_block=(1, 1), visualize=False)

            # 5. Edge features
            horizontal_edges = prewitt_h(gray_image)
            vertical_edges = prewitt_v(gray_image)
            edge_features = np.array([
                np.mean(horizontal_edges), np.std(horizontal_edges),
                np.mean(vertical_edges), np.std(vertical_edges)
            ])

            # 6. Statistical features
            stat_features = np.array([
                np.mean(gray_image), np.std(gray_image),
                np.min(gray_image), np.max(gray_image)
            ])

            # Combine all features
            combined_features = np.concatenate([
                rgb_features, lbp_hist, hog_features[:50], edge_features, stat_features
            ])

            all_features.append(combined_features)
            all_labels.append(np.argmax(batch_labels[j]))
            total_processed += 1

X = np.array(all_features)
y = np.array(all_labels)

print(f"Feature extraction from all images complete!")
print(f"Feature matrix shape: {X.shape}")
print(f"Labels shape: {y.shape}")

# Data splitting and scaling
print("Splitting data and scaling features...")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,
                                                   random_state=42, stratify=y)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"Data splitting and scaling complete!")
print(f"Training set: {X_train_scaled.shape}")
print(f"Test set: {X_test_scaled.shape}")

# Model training and evaluation
print("Training and evaluating multiple models...")

# Define classifiers
classifiers = {
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42),
    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),
    'Gaussian Naive Bayes': GaussianNB()
}

results = {}

for name, clf in classifiers.items():
    print(f"\n{name}:")

    # Cross-validation
    cv = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(clf, X_train_scaled, y_train, cv=cv, scoring='accuracy')

    # Train on full training set
    clf.fit(X_train_scaled, y_train)

    # Predict on test set
    y_pred = clf.predict(X_test_scaled)
    test_accuracy = accuracy_score(y_test, y_pred)

    results[name] = {
        'model': clf,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'test_accuracy': test_accuracy,
        'predictions': y_pred
    }

    print(f"CV Accuracy: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
    print(f"Test Accuracy: {test_accuracy:.3f}")
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=['Almond', 'Cashew', 'Walnut']))

# Quick model evaluation summary
print("Quick Model Evaluation Summary:")
print("="*50)

# Sort models by test accuracy
sorted_models = sorted(results.items(), key=lambda x: x[1]['test_accuracy'], reverse=True)

for rank, (name, result) in enumerate(sorted_models, 1):
    print(f"{rank}. {name}:")
    print(f"   Test Accuracy: {result['test_accuracy']:.3f}")
    print(f"   CV Accuracy: {result['cv_mean']:.3f} ¬± {result['cv_std']:.3f}")
    print(f"   Stability: {'High' if result['cv_std'] < 0.03 else 'Medium' if result['cv_std'] < 0.05 else 'Low'}")

    # Check per-class performance
    y_pred = result['predictions']
    from sklearn.metrics import classification_report
    report = classification_report(y_test, y_pred, target_names=['Almond', 'Cashew', 'Walnut'], output_dict=True)

    worst_class = min(['Almond', 'Cashew', 'Walnut'], key=lambda x: report[x]['f1-score'])
    best_class = max(['Almond', 'Cashew', 'Walnut'], key=lambda x: report[x]['f1-score'])

    print(f"   Best class: {best_class} (F1: {report[best_class]['f1-score']:.3f})")
    print(f"   Worst class: {worst_class} (F1: {report[worst_class]['f1-score']:.3f})")
    print()

# Select and save top 3 models
print("Selecting and saving top 3 models...")

# Get top 3 models by test accuracy
sorted_models = sorted(results.items(), key=lambda x: x[1]['test_accuracy'], reverse=True)
top_3_models = sorted_models[:3]

print("Top 3 models selected:")
for rank, (name, result) in enumerate(top_3_models, 1):
    print(f"{rank}. {name}: {result['test_accuracy']:.3f}")

# Save top 3 models
for rank, (name, result) in enumerate(top_3_models, 1):
    model_filename = f'nut_model_rank{rank}_{name.lower().replace(" ", "_")}.pkl'
    with open(model_filename, 'wb') as f:
        pickle.dump(result['model'], f)
    print(f"Saved: {model_filename}")

# Save the scaler (needed for all models)
with open('nut_scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

# Save the best model separately for easy access
best_model_name = top_3_models[0][0]
best_model = top_3_models[0][1]['model']
with open('best_nut_model.pkl', 'wb') as f:
    pickle.dump(best_model, f)

print(f"Best model ({best_model_name}) saved as 'best_nut_model.pkl'")

# Download all model files from Colab
print("Downloading trained models and files...")
from google.colab import files

# Download the main files
files.download('best_nut_model.pkl')
files.download('nut_scaler.pkl')

# Download top 3 models (optional backup)
files.download('nut_model_rank1_random_forest.pkl')
files.download('nut_model_rank2_logistic_regression.pkl')
files.download('nut_model_rank3_svm_(rbf).pkl')

# Download visualization files
files.download('nut_feature_extraction_visualization.png')
files.download('nut_samples.png')

# Download all model files from Colab
print("Downloading trained models and files...")
from google.colab import files